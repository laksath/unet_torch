{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1 # or any of your favorite number \n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the device to be used for training and evaluation\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# determine if we will be pinning memory during data loading\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize learning rate, number of epochs to train for, and the batch size\n",
    "INIT_LR = 0.001\n",
    "NUM_EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# define threshold to filter weak predictions\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# define the path to the base output directory\n",
    "BASE_OUTPUT = \"output\"\n",
    "\n",
    "# define the path to the output serialized model, model training\n",
    "# plot, and testing image paths\n",
    "MODEL_PATH = os.path.join(BASE_OUTPUT, \"unet.pth\")\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = [\"benign_image/\", \"benign_mask/\", \"malignant_image/\",\"malignant_mask/\", \"normal_image/\", \"normal_mask/\"]\n",
    "dataset = ['dataset/','train/', 'test/', 'validation/']\n",
    "\n",
    "train_test_valid = [[[], [], []], [[], [], []], [[], [], []]]\n",
    "\n",
    "for i in range(1, len(dataset)):\n",
    "    for j in range(3):\n",
    "    # for j in range(2):\n",
    "        for k in range(len(os.listdir(dataset[0]+dataset[i]+subdir[j*2]))):\n",
    "            train_test_valid[i-1][0].append(plt.imread(\n",
    "                dataset[0]+dataset[i]+subdir[j*2]+str(k)+\".jpeg\"))\n",
    "            train_test_valid[i-1][1].append(plt.imread(\n",
    "                dataset[0]+dataset[i]+subdir[j*2+1]+str(k)+\".jpeg\"))\n",
    "            train_test_valid[i-1][2].append(j)\n",
    "\n",
    "X_train_npy = np.asarray(train_test_valid[0][0], dtype=np.float32)/255\n",
    "y_train_npy = np.asarray(train_test_valid[0][1], dtype=np.float32)/255\n",
    "\n",
    "X_test_npy = np.asarray(train_test_valid[1][0], dtype=np.float32)/255\n",
    "y_test_npy = np.asarray(train_test_valid[1][1], dtype=np.float32)/255\n",
    "\n",
    "X_valid_npy = np.asarray(train_test_valid[2][0], dtype=np.float32)/255\n",
    "y_valid_npy = np.asarray(train_test_valid[2][1], dtype=np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegregateData(dataset, subdir):\n",
    "\n",
    "    l = [\n",
    "            [\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "            ], \n",
    "            [\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "            ],\n",
    "            [\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "                [[], [], []],\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        for k in range(3):\n",
    "            dir_l = os.listdir(dataset[0]+dataset[i]+subdir[k*2])\n",
    "            dir_l2 = os.listdir(dataset[0]+dataset[i]+subdir[k*2+1])\n",
    "\n",
    "            l1 = []\n",
    "            for j in range(len(dir_l)):\n",
    "                l1.append(plt.imread(dataset[0]+dataset[i]+subdir[k*2]+dir_l[j]))\n",
    "            \n",
    "            l2 = []\n",
    "            for j in range(len(dir_l2)):\n",
    "                l2.append(plt.imread(dataset[0]+dataset[i]+subdir[k*2+1]+dir_l2[j]))\n",
    "\n",
    "            l3=[]\n",
    "            for j in range(len(dir_l2)):\n",
    "                q=[0,0,0]\n",
    "                q[k]=1\n",
    "                l3.append(q)\n",
    "\n",
    "            l[i-1][k][0] = np.asarray(l1, dtype=np.float32)/255\n",
    "            l[i-1][k][1] = np.asarray(l2, dtype=np.float32)/255\n",
    "            l[i-1][k][2] = l3\n",
    "\n",
    "    return l\n",
    "\n",
    "l = SegregateData(dataset, subdir)\n",
    "\n",
    "# X_train_benign   --> l[0][0][0]  # X_test_benign   --> l[1][0][0]  # X_validation_benign   --> l[2][0][0]\n",
    "# y_train_benign   --> l[0][0][1]  # y_test_benign   --> l[1][0][1]  # y_validation_benign   --> l[2][0][1]\n",
    "# X_train_malgiant --> l[0][1][0]  # X_test_malgiant --> l[1][1][0]  # X_validation_malgiant --> l[2][1][0]\n",
    "# y_train_malgiant --> l[0][1][1]  # y_test_malgiant --> l[1][1][1]  # y_validation_malgiant --> l[2][1][1]\n",
    "# X_train_normal   --> l[0][2][0]  # X_test_normal   --> l[1][2][0]  # X_validation_normal   --> l[2][2][0]\n",
    "# y_train_normal   --> l[0][2][1]  # y_test_normal   --> l[1][2][1]  # y_validation_normal   --> l[2][2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "\n",
    "\tdef __init__(self, X, y, transforms):\n",
    "\t\tself.X = X\n",
    "\t\tself.y = y\n",
    "\t\tself.transforms = transforms\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.y)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\timage = self.X[idx]\n",
    "\t\tmask = self.y[idx]\n",
    "  \n",
    "\t\tif self.transforms is not None:\n",
    "\t\t\timage = self.transforms(image)\n",
    "\t\t\tmask = self.transforms(mask)\n",
    "   \n",
    "\t\t# return a tuple of the image and its mask\n",
    "\t\treturn (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "            \n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max = nn.MaxPool2d(2)\n",
    "        self.conv_block = DoubleConv(in_channels, out_channels)\n",
    "        # self.dropout = nn.Dropout2d(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv = self.conv_block(x)\n",
    "        pool = self.max(conv)\n",
    "        # drop = self.dropout(pool)\n",
    "        \n",
    "        # return conv, drop\n",
    "        return conv, pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderB1(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv_block = DoubleConv(mid_channels, out_channels)\n",
    "        # self.dropout = nn.Dropout2d(p=0.3)\n",
    "    \n",
    "    def forward(self, x, skip_features, skip_features_b2):\n",
    "\n",
    "        x = self.conv_transpose(x)\n",
    "        x = torch.cat([x, skip_features, skip_features_b2],dim=1)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.conv_block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DecoderB2(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv_block = DoubleConv(in_channels, out_channels)\n",
    "        # self.dropout = nn.Dropout2d(p=0.3)\n",
    "    \n",
    "    def forward(self, x, skip_features):\n",
    "\n",
    "        conv_transpose = self.conv_transpose(x)\n",
    "        x = torch.cat([conv_transpose, skip_features],dim=1)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.conv_block(x)\n",
    "\n",
    "        return x, conv_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch1(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block = DoubleConv(in_channels, mid_channels)\n",
    "        self.conv_2d = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.conv_2d(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Branch2(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block = DoubleConv(in_channels, mid_channels)\n",
    "        self.conv_2d = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.conv_2d(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_shape=256, n_input_channels=3, n_output_channels_b1=1, n_output_channels_b2=3, n_features=64, latent_dim=128):\n",
    "        super(UNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.down1 = Encoder(n_input_channels, n_features)\n",
    "        self.down2 = Encoder(n_features, n_features*2)\n",
    "        self.down3 = Encoder(n_features*2, n_features*4)\n",
    "        self.down4 = Encoder(n_features*4, n_features*8)\n",
    "        \n",
    "        self.bridge = DoubleConv(n_features*8, n_features*16)\n",
    "        \n",
    "        self.upb1_1 = DecoderB1(n_features*16,n_features*24, n_features*8)\n",
    "        self.upb1_2 = DecoderB1(n_features*8,n_features*12, n_features*4)\n",
    "        self.upb1_3 = DecoderB1(n_features*4,n_features*6, n_features*2)\n",
    "        self.upb1_4 = DecoderB1(n_features*2,n_features*3, n_features)\n",
    "        \n",
    "        flatten_size = n_features*16 * int(input_shape/16) * int(input_shape/16)\n",
    "        \n",
    "        self.intermediate1 = nn.Sequential(\n",
    "            nn.Linear(flatten_size, latent_dim*2),\n",
    "            nn.BatchNorm1d(latent_dim*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(latent_dim*2, latent_dim)\n",
    "        self.fc_var = nn.Linear(latent_dim*2, latent_dim)\n",
    "        \n",
    "        self.decoder_input = nn.Sequential(\n",
    "            nn.Linear(latent_dim, flatten_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.upb2_1 = DecoderB2(n_features*16, n_features*8)\n",
    "        self.upb2_2 = DecoderB2(n_features*8, n_features*4)\n",
    "        self.upb2_3 = DecoderB2(n_features*4, n_features*2)\n",
    "        self.upb2_4 = DecoderB2(n_features*2, n_features)\n",
    "        \n",
    "        self.outchannel_b1_grayscale = Branch1(n_features, n_features, n_output_channels_b1)\n",
    "        self.outchannel_b1_rgb = Branch2(n_features, n_features, n_output_channels_b2)\n",
    "        self.outchannel_b2_grayscale = Branch2(n_features, n_features, n_output_channels_b2)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return eps * std + mu\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv1, pool1 = self.down1(x)\n",
    "        conv2, pool2 = self.down2(pool1)\n",
    "        conv3, pool3 = self.down3(pool2)\n",
    "        conv4, pool4 = self.down4(pool3)\n",
    "        \n",
    "        bridge = self.bridge(pool4)\n",
    "        \n",
    "        #2nd branch vae\n",
    "        \n",
    "        flattened_bridge = torch.flatten(bridge, start_dim=1)\n",
    "        intermediate1 = self.intermediate1(flattened_bridge)\n",
    "        \n",
    "        mu = self.fc_mu(intermediate1)\n",
    "        log_var = self.fc_var(intermediate1)\n",
    "        \n",
    "        z = self.reparameterize(mu,log_var)\n",
    "        \n",
    "        result = self.decoder_input(z)\n",
    "        reshaped_result = result.view(-1, self.n_features*16, int(self.input_shape/16),int(self.input_shape/16))\n",
    "        \n",
    "        # 2nd branch\n",
    "        decoder_b2_1,decoder_b2_conv_transpose_1 = self.upb2_1(reshaped_result, conv4)\n",
    "        decoder_b2_2,decoder_b2_conv_transpose_2 = self.upb2_2(decoder_b2_1, conv3)\n",
    "        decoder_b2_3,decoder_b2_conv_transpose_3 = self.upb2_3(decoder_b2_2, conv2)\n",
    "        decoder_b2_4,decoder_b2_conv_transpose_4 = self.upb2_4(decoder_b2_3, conv1)\n",
    "                \n",
    "        b2_rgb = self.outchannel_b2_grayscale(decoder_b2_4)\n",
    "        \n",
    "        # 1st branch\n",
    "        decoder_b1_1 = self.upb1_1(bridge, decoder_b2_conv_transpose_1, conv4)\n",
    "        decoder_b1_2 = self.upb1_2(decoder_b1_1, decoder_b2_conv_transpose_2, conv3)\n",
    "        decoder_b1_3 = self.upb1_3(decoder_b1_2, decoder_b2_conv_transpose_3, conv2)\n",
    "        decoder_b1_4 = self.upb1_4(decoder_b1_3, decoder_b2_conv_transpose_4, conv1)\n",
    "                \n",
    "        b1_gry = self.outchannel_b1_grayscale(decoder_b1_4)\n",
    "        b1_rgb = self.outchannel_b1_rgb(decoder_b1_4)\n",
    "        \n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "        \n",
    "        return b1_gry, b1_rgb, b2_rgb, kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dice loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1e-6):\n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=float('inf')):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        \n",
    "    def __call__(self, current_valid_loss, epoch, model, optimizer):\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            print(\"Best validation dice loss: {:.4f}\".format(self.best_valid_loss)+f\" , Saving best model for epoch: {epoch+1}.\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, MODEL_PATH)\n",
    "\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return model, optimizer, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 897 examples in the training set...\n",
      "[INFO] found 303 examples in the validation set...\n"
     ]
    }
   ],
   "source": [
    "# define transformations\n",
    "transforms_ = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# create the train and test datasets\n",
    "trainDS = SegmentationDataset(X=X_train_npy, y=y_train_npy, transforms=transforms_)\n",
    "validDS = SegmentationDataset(X=X_valid_npy, y=y_valid_npy, transforms=transforms_)\n",
    "\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(validDS)} examples in the validation set...\")\n",
    "\n",
    "# create the training and test data loaders\n",
    "trainLoader = DataLoader(trainDS, batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,num_workers=os.cpu_count(),shuffle=True,drop_last=True)\n",
    "validLoader = DataLoader(validDS, batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,num_workers=os.cpu_count(),shuffle=True,drop_last=True)\n",
    "\n",
    "# initialize our UNet model\n",
    "n_features = 64\n",
    "input_shape= 256\n",
    "\n",
    "unet = UNet(input_shape=input_shape, n_input_channels=3, n_output_channels_b1=1,\n",
    "            n_output_channels_b2=3, n_features= n_features, latent_dim=128).to(DEVICE)\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "\n",
    "# initialize loss function and optimizer\n",
    "optimizer = Adam(unet.parameters(), lr=INIT_LR, weight_decay=1e-5)\n",
    "\n",
    "dice = DiceLoss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# calculate steps per epoch for training and valid set\n",
    "trainSteps = len(trainDS) // BATCH_SIZE\n",
    "validSteps = len(validDS) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[INFO] EPOCH: 1/4\n",
      "Train Loss : 3.4224, Train Dice Loss : 0.8449, Train MSE B1 ip : 0.0225, Train MSE B2 ip : 0.0159, Train MSE B1 B2 : 0.0027, Train KLD Loss  : 2.5365\n",
      "Valid Loss : 0.3358, Valid Dice Loss : 0.8540, Valid MSE B1 ip : 0.0608, Valid MSE B2 ip : 0.0188, Valid MSE B1 B2 : 0.0342, Valid KLD Loss  : 0.0769\n",
      "Best validation dice loss: 0.8540 , Saving best model for epoch: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:07<03:22, 67.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:14<03:42, 74.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1973408/3872651982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# add the loss to the total training loss so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize a dictionary to store training history\n",
    "train_history = {\n",
    "    \"train_loss\": [],\n",
    "\t\"train_dice_loss\": [],\n",
    "\t\"train_mse_b1_ip\": [],\n",
    "\t\"train_mse_b2_ip\": [],\n",
    "\t\"train_mse_b1_b2\": [],\n",
    "\t\"train_kld_loss_\": [],\n",
    "}\n",
    "\n",
    "valid_history = {\n",
    "\t\"valid_loss\": [],\n",
    "    \"valid_dice_loss\": [],\n",
    "\t\"valid_mse_b1_ip\": [],\n",
    "\t\"valid_mse_b2_ip\": [],\n",
    "\t\"valid_mse_b1_b2\": [],\n",
    "\t\"valid_kld_loss_\": [],\n",
    "}\n",
    "\n",
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "\tprint(\"-\"*150)\n",
    "\n",
    "\t# set the model in training mode\n",
    "\tunet.train()\n",
    " \n",
    "\t# initialize the total training and validation loss\n",
    "\ttotal_train_loss = 0\n",
    "\n",
    "\ttotal_train_dice_loss = 0\n",
    "\ttotal_train_mse_b1_ip = 0\n",
    "\ttotal_train_mse_b2_ip = 0\n",
    "\ttotal_train_mse_b1_b2 = 0\n",
    "\ttotal_train_kld_loss_ = 0\n",
    " \n",
    "\ttotal_valid_loss = 0\n",
    " \n",
    "\ttotal_valid_dice_loss = 0\n",
    "\ttotal_valid_mse_b1_ip = 0\n",
    "\ttotal_valid_mse_b2_ip = 0\n",
    "\ttotal_valid_mse_b1_b2 = 0\n",
    "\ttotal_valid_kld_loss_ = 0\n",
    "\n",
    "\t# loop over the training set\n",
    "\tfor (i, (x, y)) in enumerate(trainLoader):\n",
    "\t\t# print(i)\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "  \n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "  \n",
    "\t\tpred_b1_gry, pred_b1_rgb, pred_b2_rgb, kld_loss = unet(x)\n",
    "\n",
    "\t\tdice_loss = dice(pred_b1_gry, y)\n",
    "\t\tmse_b1_ip = mse(pred_b1_rgb.view(-1), x.view(-1))\n",
    "\t\tmse_b2_ip = mse(pred_b2_rgb.view(-1), x.view(-1))\n",
    "\t\tmse_b1_b2 = mse(pred_b1_rgb.view(-1), pred_b2_rgb.view(-1))\n",
    "\n",
    "\t\tloss = dice_loss + mse_b1_ip + mse_b2_ip + mse_b1_b2 + kld_loss\n",
    "\n",
    "\t\t# first, zero out any previously accumulated gradients, then\n",
    "\t\t# perform backpropagation, and then update model parameters\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t# add the loss to the total training loss so far\n",
    "  \n",
    "\t\ttotal_train_dice_loss += dice_loss\n",
    "\t\ttotal_train_mse_b1_ip += mse_b1_ip\n",
    "\t\ttotal_train_mse_b2_ip += mse_b2_ip\n",
    "\t\ttotal_train_mse_b1_b2 += mse_b1_b2\n",
    "\t\ttotal_train_kld_loss_ += kld_loss\n",
    "  \n",
    "\t\ttotal_train_loss += loss\n",
    "\t\n",
    " \n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "    \n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tunet.eval()\n",
    "  \n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x_v, y_v) in validLoader:\n",
    "      \n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x_v, y_v) = (x_v.to(DEVICE), y_v.to(DEVICE))\n",
    "\n",
    "\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tvalid_pred_b1_gry, valid_pred_b1_rgb, valid_pred_b2_rgb, valid_kld_loss = unet(x_v)\n",
    "\n",
    "\t\t\tvalid_dice_loss = dice(valid_pred_b1_gry, y_v)\n",
    "\t\t\tvalid_mse_b1_ip = mse(valid_pred_b1_rgb.view(-1), x_v.view(-1))\n",
    "\t\t\tvalid_mse_b2_ip = mse(valid_pred_b2_rgb.view(-1), x_v.view(-1))\n",
    "\t\t\tvalid_mse_b1_b2 = mse(valid_pred_b1_rgb.view(-1), valid_pred_b2_rgb.view(-1))\n",
    "\n",
    "\t\t\tvalid_loss = valid_dice_loss + valid_mse_b1_ip + valid_mse_b2_ip + valid_mse_b1_b2 + valid_kld_loss\n",
    "   \n",
    "\t\t\t# add the loss to the total validation loss so far\n",
    "\t\t\ttotal_valid_dice_loss += valid_dice_loss\n",
    "\t\t\ttotal_valid_mse_b1_ip += valid_mse_b1_ip\n",
    "\t\t\ttotal_valid_mse_b2_ip += valid_mse_b2_ip\n",
    "\t\t\ttotal_valid_mse_b1_b2 += valid_mse_b1_b2\n",
    "\t\t\ttotal_valid_kld_loss_ += valid_kld_loss\n",
    "   \n",
    "\t\t\ttotal_valid_loss += valid_loss\n",
    "   \n",
    "\t# calculate the average training loss\n",
    "\tavg_train_loss = total_train_loss / trainSteps\n",
    " \n",
    "\tavg_train_dice_loss = total_train_dice_loss / trainSteps\n",
    "\tavg_train_mse_b1_ip = total_train_mse_b1_ip / trainSteps\n",
    "\tavg_train_mse_b2_ip = total_train_mse_b2_ip / trainSteps\n",
    "\tavg_train_mse_b1_b2 = total_train_mse_b1_b2 / trainSteps\n",
    "\tavg_train_kld_loss_ = total_train_kld_loss_ / trainSteps\n",
    "   \n",
    "\t# calculate the average validation loss\n",
    "\tavg_valid_loss = total_valid_loss / validSteps\n",
    " \n",
    "\tavg_valid_dice_loss = total_valid_dice_loss / validSteps\n",
    "\tavg_valid_mse_b1_ip = total_valid_mse_b1_ip / validSteps\n",
    "\tavg_valid_mse_b2_ip = total_valid_mse_b2_ip / validSteps\n",
    "\tavg_valid_mse_b1_b2 = total_valid_mse_b1_b2 / validSteps\n",
    "\tavg_valid_kld_loss_ = total_valid_kld_loss_ / validSteps\n",
    " \n",
    "\t# update our training history\n",
    "\n",
    "\ttrain_history[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    " \n",
    "\ttrain_history[\"train_dice_loss\"].append(avg_train_dice_loss.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b1_ip\"].append(avg_train_mse_b1_ip.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b2_ip\"].append(avg_train_mse_b2_ip.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b1_b2\"].append(avg_train_mse_b1_b2.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_kld_loss_\"].append(avg_train_kld_loss_.cpu().detach().numpy())\n",
    " \n",
    "\tvalid_history[\"valid_loss\"].append(avg_valid_loss.cpu().detach().numpy())\n",
    " \n",
    "\tvalid_history[\"valid_dice_loss\"].append(avg_valid_dice_loss.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b1_ip\"].append(avg_valid_mse_b1_ip.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b2_ip\"].append(avg_valid_mse_b2_ip.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b1_b2\"].append(avg_valid_mse_b1_b2.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_kld_loss_\"].append(avg_valid_kld_loss_.cpu().detach().numpy())\n",
    " \n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "\n",
    "\tprint(\"Train Loss : {:.4f}, Train Dice Loss : {:.4f}, Train MSE B1 ip : {:.4f}, Train MSE B2 ip : {:.4f}, Train MSE B1 B2 : {:.4f}, Train KLD Loss  : {:.4f}\"\n",
    "    .format(avg_train_loss, avg_train_dice_loss, avg_train_mse_b1_ip, avg_train_mse_b2_ip, avg_train_mse_b1_b2, avg_train_kld_loss_))\n",
    " \n",
    "\tprint(\"Valid Loss : {:.4f}, Valid Dice Loss : {:.4f}, Valid MSE B1 ip : {:.4f}, Valid MSE B2 ip : {:.4f}, Valid MSE B1 B2 : {:.4f}, Valid KLD Loss  : {:.4f}\"\n",
    "    .format(avg_valid_loss, avg_valid_dice_loss, avg_valid_mse_b1_ip, avg_valid_mse_b2_ip, avg_valid_mse_b1_b2, avg_valid_kld_loss_))\n",
    "\n",
    "\tsave_best_model(avg_valid_dice_loss, e, unet, optimizer)\n",
    "\t\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"-\"*150)\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(train_history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(valid_history[\"valid_loss\"], label=\"valid_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig(PLOT_PATH)\n",
    "# serialize the model to disk\n",
    "# torch.save(unet, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot(origImage, origMask, predMask):\n",
    "\t# initialize our figure\n",
    "\tfigure, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "\t# plot the original image, its mask, and the predicted mask\n",
    "\tax[0].imshow(origImage)\n",
    "\tax[1].imshow(origMask)\n",
    "\tax[2].imshow(predMask)\n",
    "\t# set the titles of the subplots\n",
    "\tax[0].set_title(\"Image\")\n",
    "\tax[1].set_title(\"Original Mask\")\n",
    "\tax[2].set_title(\"Predicted Mask\")\n",
    "\t# set the layout of the figure and display it\n",
    "\tfigure.tight_layout()\n",
    "\tfigure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X, y):\n",
    "\t# set model to evaluation mode\n",
    "\tmodel.eval()\n",
    "\t# turn off gradient tracking\n",
    "\twith torch.no_grad():\n",
    "    \n",
    "\t\torig = X.copy()\n",
    "\t\tgtMask = y.copy()\n",
    "  \n",
    "  \n",
    "  \t\t# make the channel axis to be the leading one, add a batch dimension, create a PyTorch tensor, and flash it to the current device\n",
    "\t\timage = np.transpose(X, (2, 0, 1))\n",
    "\t\timage = np.expand_dims(image, 0)\n",
    "\t\timage = torch.from_numpy(image).to(DEVICE)\n",
    "  \n",
    "\t\t# make the prediction, and convert the result to a NumPy array\n",
    "\t\tpredMask = model(image)[0].squeeze()\n",
    "\t\tpredMask = predMask.cpu().numpy()\n",
    "  \n",
    "\t\t# filter out the weak predictions and convert them to integers\n",
    "\t\tpredMask = (predMask > THRESHOLD) * 255\n",
    "\t\tpredMask = predMask.astype(np.uint8)\n",
    "\n",
    "\t\t# prepare a plot for visualization\n",
    "\t\tprepare_plot(orig, gtMask, predMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# unet = torch.load(MODEL_PATH).to(DEVICE)\n",
    "\n",
    "# iterate over the randomly selected test image paths\n",
    "# for i in range(10):\n",
    "\t# make predictions and visualize the results\n",
    "\t# make_predictions(unet, X_train_npy[i], y_train_npy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our model from disk and flash it to the current device\n",
    "unet2 = UNet(\n",
    "    input_shape=input_shape, n_input_channels=3, n_output_channels_b1=1, n_output_channels_b2=3, n_features= n_features, latent_dim=128).to(DEVICE)\n",
    "optimizer2 = Adam(unet2.parameters(), lr=INIT_LR, weight_decay=1e-5)\n",
    "model2, optimizer2, start_epoch = load_ckp(MODEL_PATH,unet2,optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiceLoss_npy(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.multiply(y_true_f,y_pred_f)\n",
    "    score = (2. * np.sum(intersection) + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "    return (1-score).astype(np.float32)\n",
    "\n",
    "def mse_loss_npy(imageA, imageB):\n",
    "    imageA_f = imageA.flatten()\n",
    "    imageB_f = imageB.flatten()\n",
    "    return (np.sum((imageA_f - imageB_f) ** 2)/len(imageA_f)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_loss(model, X, y, d):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dice_loss = DiceLoss()\n",
    "        mse_loss = nn.MSELoss()\n",
    "        \n",
    "        orig = X.copy()\n",
    "        gtMask = y.copy()\n",
    "        gtMask = torch.from_numpy(y).to(DEVICE)\n",
    "        \n",
    "        image = np.transpose(X, (2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = torch.from_numpy(image).to(DEVICE)\n",
    "                \n",
    "        pred_b1_gry, pred_b1_rgb, pred_b2_rgb, kld_loss  = model(image)\n",
    "        pred_b1_gry = pred_b1_gry.squeeze()\n",
    "        \n",
    "        dice = dice_loss(pred_b1_gry,gtMask).cpu().numpy()\n",
    "        mse_b1_ip = mse_loss(pred_b1_rgb,image).cpu().numpy()\n",
    "        mse_b2_ip = mse_loss(pred_b2_rgb,image).cpu().numpy()\n",
    "        mse_b1_b2 = mse_loss(pred_b1_rgb,pred_b2_rgb).cpu().numpy()\n",
    "        kld = kld_loss.cpu().numpy()\n",
    "        \n",
    "        d['dice']+= dice\n",
    "        d['mse_b1_ip']+= mse_b1_ip\n",
    "        d['mse_b2_ip']+= mse_b2_ip\n",
    "        d['mse_b1_b2']+= mse_b1_b2\n",
    "        d['kld']+= kld\n",
    "        d['loss']+= (dice + mse_b1_ip + mse_b2_ip + mse_b1_b2 + kld)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_loss(model, X, y, d):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        image = np.transpose(X, (2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = torch.from_numpy(image).to(DEVICE)\n",
    "                \n",
    "        pred_b1_gry, pred_b1_rgb, pred_b2_rgb, kld_loss  = model(image)\n",
    "        \n",
    "        \n",
    "        image       = image.cpu().numpy()\n",
    "        pred_b1_gry = pred_b1_gry.squeeze().cpu().numpy()\n",
    "        pred_b1_rgb = pred_b1_rgb.cpu().numpy()\n",
    "        pred_b2_rgb = pred_b2_rgb.cpu().numpy()\n",
    "        \n",
    "        dice      = DiceLoss_npy(y, pred_b1_gry)\n",
    "        mse_b1_ip = mse_loss_npy(image, pred_b1_rgb)\n",
    "        mse_b2_ip = mse_loss_npy(image, pred_b2_rgb)\n",
    "        mse_b1_b2 = mse_loss_npy(pred_b1_rgb, pred_b2_rgb)\n",
    "        kld       = kld_loss.cpu().numpy()\n",
    "        \n",
    "        d['dice']      += dice\n",
    "        d['mse_b1_ip'] += mse_b1_ip\n",
    "        d['mse_b2_ip'] += mse_b2_ip\n",
    "        d['mse_b1_b2'] += mse_b1_b2\n",
    "        d['kld']       += kld\n",
    "        d['loss']      += (dice + mse_b1_ip + mse_b2_ip + mse_b1_b2 + kld)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_loss(model, X, y, avg=False):\n",
    "\n",
    "    d={}\n",
    "    d['dice'] = 0\n",
    "    d['mse_b1_ip'] = 0\n",
    "    d['mse_b2_ip'] = 0\n",
    "    d['mse_b1_b2'] = 0\n",
    "    d['kld'] = 0\n",
    "    d['loss'] = 0\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        get_item_loss(model2,X[i],y[i],d)\n",
    "\n",
    "    if(avg):\n",
    "        for k in d.keys():\n",
    "            d[k]/=len(y)\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dice': 0.7653534680339139,\n",
       " 'mse_b1_ip': 0.0016431875921185716,\n",
       " 'mse_b2_ip': 0.0009730681339307369,\n",
       " 'mse_b1_b2': 0.0010916614103460127,\n",
       " 'kld': 0.03034445719841199,\n",
       " 'loss': 0.7994058428699755}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_loss(model2, X_train_npy, y_train_npy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dice': 0.7655684201434108,\n",
       " 'mse_b1_ip': 0.001615089847492638,\n",
       " 'mse_b2_ip': 0.0009195483071620425,\n",
       " 'mse_b1_b2': 0.0010635176137175793,\n",
       " 'kld': 0.03329345475722461,\n",
       " 'loss': 0.8024600328687}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_loss(model2, X_valid_npy, y_valid_npy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dice': 0.7098493484740561,\n",
       " 'mse_b1_ip': 0.0015775265791354344,\n",
       " 'mse_b2_ip': 0.0008722470286847191,\n",
       " 'mse_b1_b2': 0.001097202566179863,\n",
       " 'kld': 0.025626253320815716,\n",
       " 'loss': 0.7390225804232536}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "get_total_loss(model2, X_test_npy, y_test_npy, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'dice': 104.0490011870861,\n",
      "     'kld': 6.273836106061935,\n",
      "     'loss': 111.39767634868622,\n",
      "     'mse_b1_b2': 0.1321909132238943,\n",
      "     'mse_b1_ip': 0.5515536274760962,\n",
      "     'mse_b2_ip': 0.391094466089271},\n",
      " 2: {'dice': 39.48231415450573,\n",
      "     'kld': 2.1654744744300842,\n",
      "     'loss': 42.13377137482166,\n",
      "     'mse_b1_b2': 0.05775688495486975,\n",
      "     'mse_b1_ip': 0.25032099965028465,\n",
      "     'mse_b2_ip': 0.17790465673897415},\n",
      " 3: {'dice': 40.0,\n",
      "     'kld': 0.9850189685821533,\n",
      "     'loss': 41.28168475627899,\n",
      "     'mse_b1_b2': 0.037854913069168106,\n",
      "     'mse_b1_ip': 0.1521012345328927,\n",
      "     'mse_b2_ip': 0.1067097308114171}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "183.53131534159184"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2={}\n",
    "k=0\n",
    "# for i in range(3):\n",
    "for i in range(1,2):\n",
    "    for j in range(3):\n",
    "        k+=1\n",
    "        d2[k]=get_total_loss(model2,l[i][j][0],l[i][j][1])\n",
    "\n",
    "pprint.pprint(d2)\n",
    "\n",
    "q=0\n",
    "for x in d2.values():\n",
    "    q+=x['dice']\n",
    "    \n",
    "# q/len(y_test_npy)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_benign   --> l[0][0][0]  # X_test_benign   --> l[1][0][0]  # X_validation_benign   --> l[2][0][0]\n",
    "# y_train_benign   --> l[0][0][1]  # y_test_benign   --> l[1][0][1]  # y_validation_benign   --> l[2][0][1]\n",
    "# X_train_malgiant --> l[0][1][0]  # X_test_malgiant --> l[1][1][0]  # X_validation_malgiant --> l[2][1][0]\n",
    "# y_train_malgiant --> l[0][1][1]  # y_test_malgiant --> l[1][1][1]  # y_validation_malgiant --> l[2][1][1]\n",
    "# X_train_normal   --> l[0][2][0]  # X_test_normal   --> l[1][2][0]  # X_validation_normal   --> l[2][2][0]\n",
    "# y_train_normal   --> l[0][2][1]  # y_test_normal   --> l[1][2][1]  # y_validation_normal   --> l[2][2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(torch.Tensor(y_train_npy),torch.Tensor(y_train_npy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "\tprint(\"-\"*128)\n",
    "\n",
    "\t# set the model in training mode\n",
    "\tunet.train()\n",
    " \n",
    "\t# initialize the total training and validation loss\n",
    "\ttotal_train_loss = 0\n",
    "\n",
    "\ttotal_train_dice_loss = 0\n",
    "\ttotal_train_mse_b1_ip = 0\n",
    "\ttotal_train_mse_b2_ip = 0\n",
    "\ttotal_train_mse_b1_b2 = 0\n",
    "\ttotal_train_kld_loss_ = 0\n",
    " \n",
    "\ttotal_valid_loss = 0\n",
    " \n",
    "\ttotal_valid_dice_loss = 0\n",
    "\ttotal_valid_mse_b1_ip = 0\n",
    "\ttotal_valid_mse_b2_ip = 0\n",
    "\ttotal_valid_mse_b1_b2 = 0\n",
    "\ttotal_valid_kld_loss_ = 0\n",
    "\n",
    "\t# loop over the training set\n",
    "\tfor (i, (x, y)) in enumerate(trainLoader):\n",
    "\t\t# print(i)\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "  \n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "  \n",
    "\t\tpred_b1_gry, pred_b1_rgb, pred_b2_rgb, kld_loss = unet(x)\n",
    "\n",
    "\t\tdice_loss = dice(pred_b1_gry, y)\n",
    "\t\tmse_b1_ip = mse(pred_b1_rgb.view(-1), x.view(-1))\n",
    "\t\tmse_b2_ip = mse(pred_b2_rgb.view(-1), x.view(-1))\n",
    "\t\tmse_b1_b2 = mse(pred_b1_rgb.view(-1), pred_b2_rgb.view(-1))\n",
    "\n",
    "\t\tloss = dice_loss + mse_b1_ip + mse_b2_ip + mse_b1_b2 + kld_loss\n",
    "\n",
    "\t\t# first, zero out any previously accumulated gradients, then\n",
    "\t\t# perform backpropagation, and then update model parameters\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t# add the loss to the total training loss so far\n",
    "  \n",
    "\t\ttotal_train_dice_loss += dice_loss\n",
    "\t\ttotal_train_mse_b1_ip += mse_b1_ip\n",
    "\t\ttotal_train_mse_b2_ip += mse_b2_ip\n",
    "\t\ttotal_train_mse_b1_b2 += mse_b1_b2\n",
    "\t\ttotal_train_kld_loss_ += kld_loss\n",
    "  \n",
    "\t\ttotal_train_loss += loss\n",
    "\t\n",
    " \n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "    \n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tunet.eval()\n",
    "  \n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in validLoader:\n",
    "      \n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
    "\n",
    "\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred_b1_gry, pred_b1_rgb, pred_b2_rgb, kld_loss = unet(x)\n",
    "\n",
    "\t\t\tdice_loss = dice(pred_b1_gry, y)\n",
    "\t\t\tmse_b1_ip = mse(pred_b1_rgb.view(-1), x.view(-1))\n",
    "\t\t\tmse_b2_ip = mse(pred_b2_rgb.view(-1), x.view(-1))\n",
    "\t\t\tmse_b1_b2 = mse(pred_b1_rgb.view(-1), pred_b2_rgb.view(-1))\n",
    "\n",
    "\t\t\tloss = dice_loss + mse_b1_ip + mse_b2_ip + mse_b1_b2 + kld_loss\n",
    "   \n",
    "\t\t\t# add the loss to the total validation loss so far\n",
    "\t\t\ttotal_valid_dice_loss += dice_loss\n",
    "\t\t\ttotal_valid_mse_b1_ip += mse_b1_ip\n",
    "\t\t\ttotal_valid_mse_b2_ip += mse_b2_ip\n",
    "\t\t\ttotal_valid_mse_b1_b2 += mse_b1_b2\n",
    "\t\t\ttotal_valid_kld_loss_ += kld_loss\n",
    "   \n",
    "\t\t\ttotal_valid_loss += loss\n",
    "   \n",
    "\t# calculate the average training loss\n",
    "\tavg_train_loss = total_train_loss / trainSteps\n",
    " \n",
    "\tavg_train_dice_loss = total_train_dice_loss / trainSteps\n",
    "\tavg_train_mse_b1_ip = total_train_mse_b1_ip / trainSteps\n",
    "\tavg_train_mse_b2_ip = total_train_mse_b2_ip / trainSteps\n",
    "\tavg_train_mse_b1_b2 = total_train_mse_b1_b2 / trainSteps\n",
    "\tavg_train_kld_loss_ = total_train_kld_loss_ / trainSteps\n",
    "   \n",
    "\t# calculate the average validation loss\n",
    "\tavg_valid_loss = total_valid_loss / trainSteps\n",
    " \n",
    "\tavg_valid_dice_loss = total_valid_dice_loss / validSteps\n",
    "\tavg_valid_mse_b1_ip = total_valid_mse_b1_ip / validSteps\n",
    "\tavg_valid_mse_b2_ip = total_valid_mse_b2_ip / validSteps\n",
    "\tavg_valid_mse_b1_b2 = total_valid_mse_b1_b2 / validSteps\n",
    "\tavg_valid_kld_loss_ = total_valid_kld_loss_ / validSteps\n",
    " \n",
    "\t# update our training history\n",
    "\n",
    "\ttrain_history[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    " \n",
    "\ttrain_history[\"train_dice_loss\"].append(avg_train_dice_loss.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b1_ip\"].append(avg_train_mse_b1_ip.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b2_ip\"].append(avg_train_mse_b2_ip.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_mse_b1_b2\"].append(avg_train_mse_b1_b2.cpu().detach().numpy())\n",
    "\ttrain_history[\"train_kld_loss_\"].append(avg_train_kld_loss_.cpu().detach().numpy())\n",
    " \n",
    "\tvalid_history[\"valid_loss\"].append(avg_valid_loss.cpu().detach().numpy())\n",
    " \n",
    "\tvalid_history[\"valid_dice_loss\"].append(avg_valid_dice_loss.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b1_ip\"].append(avg_valid_mse_b1_ip.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b2_ip\"].append(avg_valid_mse_b2_ip.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_mse_b1_b2\"].append(avg_valid_mse_b1_b2.cpu().detach().numpy())\n",
    "\tvalid_history[\"valid_kld_loss_\"].append(avg_valid_kld_loss_.cpu().detach().numpy())\n",
    " \n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
    "\n",
    "\tprint(\"Train Dice Loss : {:.4f}, Train MSE B1 ip : {:.4f}, Train MSE B2 ip : {:.4f}, Train MSE B1 B2 : {:.4f}, Train KLD Loss  : {:.4f}\"\n",
    "    .format(avg_train_dice_loss, avg_train_mse_b1_ip, avg_train_mse_b2_ip, avg_train_mse_b1_b2, avg_train_kld_loss_))\n",
    " \n",
    "\tprint(\"Valid Dice Loss : {:.4f}, Valid MSE B1 ip : {:.4f}, Valid MSE B2 ip : {:.4f}, Valid MSE B1 B2 : {:.4f}, Valid KLD Loss  : {:.4f}\"\n",
    "    .format(avg_valid_dice_loss, avg_valid_mse_b1_ip, avg_valid_mse_b2_ip, avg_valid_mse_b1_b2, avg_valid_kld_loss_))\n",
    "\n",
    "\tsave_best_model(avg_valid_dice_loss, e, unet, optimizer)\n",
    "\t\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"-\"*128)\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb74040e7540b07eacd930ce15e6b854a92adeabedfa59448a5e0c36812bf126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
